{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Продвинутое машинное обучение: ДЗ 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Студент: Бакулев Владимир Леонидович\n",
    "\n",
    "Группа: MADE-DS-22\n",
    "\n",
    "Почта: vlbakulev@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import operator\n",
    "from collections import Counter\n",
    "from copy import copy\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from nltk import ngrams\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "\n",
    "Реализуйте базовый частотный метод по Шерлоку Холмсу:\n",
    "- подсчитайте частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить);\n",
    "- возьмите какие-нибудь тестовые тексты (нужно взять по меньшей мере 2-3 предложения, иначе вряд ли сработает), зашифруйте их посредством случайной перестановки символов;\n",
    "- расшифруйте их таким частотным методом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Решение\n",
    "\n",
    "Дешифровальный словарь:\n",
    "- ключи: отсортированный по частоте употребления список символов в тестовом тексте\n",
    "- значения: отсортированный по частоте употребления список символов в большом тексте (Война и мир)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABC = ' абвгдеёжзийклмнопрстуфхцчшщъыьэюя'\n",
    "\n",
    "WAR_AND_PEACE_PATH = './texts/WarAndPeace.txt'\n",
    "ANNA_KARENINA_PATH = './texts/AnnaKarenina.txt'\n",
    "ANY_TEXT_PATH = './texts/part_from_Dovlatov_Nashy.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text(text_path):\n",
    "    \"\"\"\n",
    "    Считываем текст, после чего удаляем из текста табуляцию, переносы, \n",
    "    знаки препинания и приводим все к нижнему регистру\n",
    "    \"\"\"\n",
    "    clean_text = ''\n",
    "    with open(text_path, 'r') as fin:\n",
    "        for line in fin:\n",
    "            line_without_punctuation = re.sub(r\"\\W+\", \" \", line.lower())\n",
    "            char_in_abc = ''.join([char for char in line_without_punctuation if char in list(ABC)])\n",
    "            clean_text = ''.join([clean_text, char_in_abc])\n",
    "    return clean_text\n",
    "\n",
    "def calculate_ngramm(text, count_char_in_ngramm=1):\n",
    "    text_in_ngramm = [''.join(gram) for gram in ngrams(text, count_char_in_ngramm)]\n",
    "    counter_ngramm = dict(Counter(list(text_in_ngramm)))\n",
    "    sorted_counter_ngramm = dict(sorted(\n",
    "        counter_ngramm.items(), \n",
    "        key=operator.itemgetter(1),\n",
    "        reverse=True\n",
    "    ))\n",
    "    return sorted_counter_ngramm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encrypt_text(text, key_dict):\n",
    "    _encrypt_text = []\n",
    "    for char in list(text):\n",
    "        _encrypt_text += key_dict[char]\n",
    "    return ''.join(_encrypt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_and_peace = prepare_text(WAR_AND_PEACE_PATH)\n",
    "any_text = prepare_text(ANY_TEXT_PATH)\n",
    "anna_karenina = prepare_text(ANNA_KARENINA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypt_ABC = 'фадщоезкжятьнюйэёъпвчцлысрбугхиш м'\n",
    "encrypt_dict = dict(zip(ABC, crypt_ABC))\n",
    "# decrypt_dict = dict(zip(crypt_ABC, ABC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "дед исаак очень много ел батоны разрезал не поперек а вдоль в гостях бабка рая постоянно за него краснела прежде чем идти в гости дед обедал это не помогало куски хлеба он складывал пополам водку пил из бокала для крем соды во время десерта просил не убирать заливное вернувшись домой с облегчением ужинал \n"
     ]
    }
   ],
   "source": [
    "print(any_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "езефтваанфёрзэифйэёоёфзюфдачёэхфпаяпзяаюфэзфъёъзпзнфафщеёюифщфоёвчмыфдаднафпамфъёвчёмээёфяафэзоёфнпавэзюафъпзжезфрзйфтечтфщфоёвчтфезефёдзеаюфшчёфэзфъёйёоаюёфнцвнтфыюздафёэфвнюаехщаюфъёъёюайфщёенцфътюфтяфдёнаюафеюмфнпзйфвёехфщёфщпзймфезвзпчафъпёвтюфэзфцдтпачифяаютщэёзфщзпэцщбтвифеёйёьфвфёдюзорзэтзйфцжтэаюф\n"
     ]
    }
   ],
   "source": [
    "encrypt_any_text = encrypt_text(any_text, key_dict=encrypt_dict)\n",
    "print(encrypt_any_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_and_peace_count_1gramm = calculate_ngramm(war_and_peace, count_char_in_ngramm=1)\n",
    "any_text_count_1gramm = calculate_ngramm(encrypt_any_text, count_char_in_ngramm=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "тат слеер обанз мнояо аи уепонч вегвагеи на додавар е ктоиз к яолпьй уеуре веь долпоьнно ге наяо рвелнаие дважта бам стпс к яолпс тат оуатеи шпо на домояеио рылрс йиауе он лриетчкеи додоием котры дси сг уореие тиь рвам лотч ко квамь талавпе дволси на ыусвепз геискноа кавныкхслз томою л оуиаябансам ыжснеи \n"
     ]
    }
   ],
   "source": [
    "sorted_1gram_in_war_and_peace = list(war_and_peace_count_1gramm.keys())\n",
    "sorted_1gram_in_any_text = list(any_text_count_1gramm.keys())\n",
    "                                \n",
    "decrypt_dict_1gram = dict(zip(sorted_1gram_in_any_text, sorted_1gram_in_war_and_peace))\n",
    "decrypt_any_text_1gram = encrypt_text(encrypt_any_text, key_dict=decrypt_dict_1gram)\n",
    "                                \n",
    "print(decrypt_any_text_1gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_decrypt(encrypt_text, decrypt_text):\n",
    "    score = 0\n",
    "    for en_char, de_char in zip(encrypt_text, decrypt_text):\n",
    "        if en_char == de_char:\n",
    "            score += 1\n",
    "    return score / len(encrypt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34967320261437906"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_decrypt(any_text, decrypt_any_text_1gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вывод:\n",
    "\n",
    "Точность 0,35 - это лучше, чем ничего, но текст разобрать невозможно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2\n",
    "\n",
    "Вряд ли в результате получилась такая уж хорошая расшифровка, разве что если вы брали в качестве тестовых данных целые рассказы. Но и Шерлок Холмс был не так уж прост: после буквы E, которая действительно выделяется частотой, дальше он анализировал уже конкретные слова и пытался угадать, какими они могли бы быть. Я не знаю, как запрограммировать такой интуитивный анализ, так что давайте просто сделаем следующий логический шаг:\n",
    "- подсчитайте частоты биграмм (т.е. пар последовательных букв) по корпусам;\n",
    "- проведите тестирование аналогично п.1, но при помощи биграмм."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Решение\n",
    "\n",
    "Аналогично предыдущему пункту, только берем не все биграммы в большом тексте, а только N самых употребимых, где N - количество биграм в тестовом тексте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_and_peace_count_2gramm = calculate_ngramm(war_and_peace, count_char_in_ngramm=2)\n",
    "any_text_count_2gramm = calculate_ngramm(encrypt_any_text, count_char_in_ngramm=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_2gram_in_war_and_peace = list(war_and_peace_count_2gramm.keys())\n",
    "sorted_2gram_in_any_text = list(any_text_count_2gramm.keys())\n",
    "\n",
    "decrypt_dict_2gram = dict(zip(\n",
    "    sorted_2gram_in_any_text, \n",
    "    sorted_2gram_in_war_and_peace[:len(sorted_2gram_in_any_text)],\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " оолан дрн  оиккеев исзс   таааиотзепуб   вн орм псне  е лйк ериатыто  оиа отьо оатасвтвсмб  ваисдат ивсо  ипгяоньолеатиго ериатгоооол чно   у ас вн он  ы бсдляьаосемн   амрьроскяа   оролоие тгелр м  аеы луа о овиодаплерэгки тс оплеоооде лй  инао   внелуоттекмб тадввн е реидуняко н дррв чпмажоихклеезкин  \n"
     ]
    }
   ],
   "source": [
    "decrypt_any_text_2gram = ''\n",
    "for gram_1, gram_2 in ngrams(encrypt_any_text, 2):\n",
    "    gram = ''.join([gram_1, gram_2])\n",
    "    de_gram = decrypt_dict_2gram[gram]\n",
    "    if decrypt_any_text_2gram == '':\n",
    "        decrypt_any_text_2gram += de_gram\n",
    "    else:\n",
    "        decrypt_any_text_2gram += de_gram[1]\n",
    "\n",
    "print(decrypt_any_text_2gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10457516339869281"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_decrypt(any_text, decrypt_any_text_2gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вывод\n",
    "\n",
    "Результат законормено никакой, так как биграмм слишком много и вероятность полного соответсвия частотности биграмм нулевая"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3\n",
    "\n",
    "Но и это ещё не всё: биграммы скорее всего тоже далеко не всегда работают. Основная часть задания — в том, как можно их улучшить:\n",
    "- предложите метод обучения перестановки символов в этом задании, основанный на MCMC-сэмплировании, но по-прежнему работающий на основе статистики биграмм;\n",
    "- реализуйте и протестируйте его, убедитесь, что результаты улучшились."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Решение\n",
    "\n",
    "Марковская цепь - это полседовательность перестановок символов в дешифровальном словаре. По ходу движения по марковской цепи будем либо принимать перестановки, либо отбрасывать. \n",
    "\n",
    "Вероятность выбора данной биграммы пропорционально частоте этой биграммы, что можно смоделировать как подбрасываение многомерной монетки. Таким образом, в качестве правдоподобия можно взять мультиномиальное распределение\n",
    "\n",
    "Общий код аналогичен коду из лекции 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dict_key(current_dict_key):\n",
    "    keys_values = list(current_dict_key.keys())\n",
    "    i, j = random.sample(list(range(len(keys_values))), 2)\n",
    "    keys_values[i], keys_values[j] = keys_values[j], keys_values[i]\n",
    "    return dict(zip(keys_values, current_dict_key.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_hastings_log_accept(l, l_new):\n",
    "    if l_new > l:\n",
    "        return True\n",
    "    else:\n",
    "        return (np.random.rand() < np.exp(l_new - l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinomial_likelihood_logpdf(\n",
    "    decrypt_dict_key,\n",
    "    text,\n",
    "    ngramm_database=war_and_peace_count_2gramm,\n",
    "    count_char_in_ngramm=2    \n",
    "):  \n",
    "    text = encrypt_text(text, key_dict=decrypt_dict_key)\n",
    "    ngram_in_text = calculate_ngramm(text, count_char_in_ngramm=count_char_in_ngramm)\n",
    "    _likelihood = 0\n",
    "    for k, v in ngram_in_text.items():\n",
    "        if ngramm_database.get(k) is not None:\n",
    "            _likelihood += v * np.log(ngramm_database[k])\n",
    "    return _likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_hastings(\n",
    "    func_log_likelihood, \n",
    "    iterations, \n",
    "    init_dict_key, \n",
    "    problem_text, \n",
    "    print_text=False\n",
    "):\n",
    "    cur_dict_key = init_dict_key\n",
    "    cur_l = func_log_likelihood(cur_dict_key)\n",
    "    samples, accept_bit = [cur_dict_key], [1]\n",
    "    for i in range(iterations):\n",
    "        new_dict_key = sample_dict_key(cur_dict_key)\n",
    "        new_l = func_log_likelihood(new_dict_key)\n",
    "        samples.append(new_dict_key)\n",
    "\n",
    "        if (metropolis_hastings_log_accept(cur_l, new_l)):\n",
    "            cur_dict_key, cur_l = new_dict_key, new_l\n",
    "            accept_bit.append(1)\n",
    "        else:\n",
    "            accept_bit.append(0)\n",
    "        if print_text:\n",
    "            if i % 1000 == 0:\n",
    "                decrypt_any_text = encrypt_text(problem_text, key_dict=cur_dict_key)\n",
    "                print(decrypt_any_text[:79])\n",
    "    return cur_dict_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "езефтваанфёрзэифйэёоёфзюфдачёэхфпаяпзяаюфэзфъёъзпзнфафщеёюифщфоёвчмыфдаднафпамф\n",
      "дед стоок абель ялаза ен гоуалх ропрепон ле ваверек о мдань м затуйч гогко рой \n",
      "вев итоод ашень мназа ел госаны ропрепол не какеред о бваль б затсяй гогдо роя \n",
      "вев итоод ажень мназа ел госаны ропрепол не какеред о бваль б затсях гогдо роя \n",
      "вев исоок ажень мназа ел потаны рогрегол не дадерек о бваль б застях попко роя \n",
      "вев исоок ажень мназа ел дотаны рогрегол не паперек о бваль б застяй додко роя \n",
      "вев исаак ожень много ел батоны разрезал не поперек а дволь д гостях бабка рая \n",
      "вев исаак очень много ел батоны разрезал не поперек а дволь д гостях бабка рая \n",
      "дед исаак очень много ел батоны разрезал не поперек а вдоль в гостях бабка рая \n",
      "дед исаак очень много ел батоны разрезал не поперек а вдоль в гостях бабка рая \n",
      "дед исаак очень много ел батоны разрезал не поперек а вдоль в гостях бабка рая \n",
      "дед исаак очень много ел батоны разрезал не поперек а вдоль в гостяю бабка рая \n",
      "дед исаак очень много ел батоны разрезал не поперек а вдоль в гостяй бабка рая \n",
      "дед исаак очень много ел батоны разрезал не поперек а вдоль в гостях бабка рая \n",
      "дед исаак очень много ел батоны разрезал не поперек а вдоль в гостях бабка рая \n",
      "дед исаак очень много ел батоны разрезал не поперек а вдоль в гостях бабка рая \n",
      "дед исаак очень много ел батоны разрезал не поперек а вдоль в гостях бабка рая \n",
      "дед исаак очень много ел батоны разрезал не поперек а вдоль в гостях бабка рая \n",
      "дед исаак очень много ел батоны разрезал не поперек а вдоль в гостях бабка рая \n",
      "дед исаак очень много ел батоны разрезал не поперек а вдоль в гостях бабка рая \n"
     ]
    }
   ],
   "source": [
    "num_samples = 20000\n",
    "decrypt_dict = dict(zip(ABC, ABC))\n",
    "war_and_peace_count_2gramm = calculate_ngramm(war_and_peace, count_char_in_ngramm=2)\n",
    "\n",
    "result_decrypt_dict = metropolis_hastings(\n",
    "    lambda x : multinomial_likelihood_logpdf(\n",
    "        x,\n",
    "        text=encrypt_any_text,\n",
    "        ngramm_database=war_and_peace_count_2gramm,\n",
    "        count_char_in_ngramm=2,\n",
    "    ), \n",
    "    iterations=num_samples, \n",
    "    init_dict_key=decrypt_dict,\n",
    "    problem_text=encrypt_any_text,\n",
    "    print_text=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "дед исаак очень много ел батоны разрезал не поперек а вдоль в гостях бабка рая постоянно за него краснела прежде чем идти в гости дед обедал это не помогало куски хлеба он складывал пополам водку пил из бокала для крем соды во время десерта просил не убирать заливное вернувшись домой с облегчением ужинал \n"
     ]
    }
   ],
   "source": [
    "decrypt_any_text = encrypt_text(encrypt_any_text, key_dict=result_decrypt_dict)\n",
    "print(decrypt_any_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_decrypt(any_text, decrypt_any_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вывод\n",
    "\n",
    "100% точность, но с 10 попытки:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4\n",
    "\n",
    "Расшифруйте сообщение:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Решение\n",
    "\n",
    "Алгоритм аналогичен п.3. Поскольку количество уникальных символов в тестовом тексте меньше, чем в рабочем алфавите, то добавим \"заглушки\" - специальные символы, которые уровняют количество уникальных букв"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹⇸↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊↹↷⇠←↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝←⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏\n"
     ]
    }
   ],
   "source": [
    "TASK_TEXT_PATH = './texts/task_text.txt'\n",
    "\n",
    "task_text = ''\n",
    "with open(TASK_TEXT_PATH, 'r') as fin:\n",
    "    for line in fin.readline():\n",
    "        task_text += line.strip()\n",
    "    \n",
    "print(task_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_task_char = list((set(task_text)))\n",
    "array_task_char += ['mock_1', 'mock_2', 'mock_3', 'mock_4', 'mock_5', 'mock_6']\n",
    "popular_char = sorted_1gram_in_war_and_peace\n",
    "decrypt_dict_for_task = dict(zip(array_task_char, popular_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ожриеыкеыизисоеяаню рчяклеириеьавсиеяаню рчяклесопжседеусайаежаагбояихепасанкле\n",
      "енси ды дишиле варбоствых иси памли варбоствых лекнл у юлага наажцевия каларых \n",
      "евси ды димиле наргосьных иси пажли наргосьных леквл у элаза ваачтения каларых \n",
      "евси ды димиле норзасьный иси погли норзасьный летвл у блоко воочшения толорый \n",
      "евти сы симиле норжатьный ити подли норжатьный леквл у блого воочшения колорый \n",
      "если вы вимите норзальный или подти норзальный текст у чтого сообшения который \n",
      "если вы вимите норжальный или подти норжальный текст у чтого сообщения который \n",
      "если вы вимите норжальный или подти норжальный текст у этого сообчения который \n",
      "если вы вичите нормальный или подти нормальный текст у этого сообщения который \n",
      "если вы вимите нордальный или почти нордальный текст у этого сообщения который \n"
     ]
    }
   ],
   "source": [
    "num_samples = 10000\n",
    "result_decrypt_dict = metropolis_hastings(\n",
    "    lambda x : multinomial_likelihood_logpdf(\n",
    "        x,\n",
    "        text=task_text,\n",
    "        ngramm_database=war_and_peace_count_2gramm,\n",
    "        count_char_in_ngramm=2,\n",
    "    ), \n",
    "    iterations=num_samples, \n",
    "    init_dict_key=decrypt_dict_for_task,\n",
    "    problem_text=task_text,\n",
    "    print_text=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "если вы вимите нордальный или почти нордальный текст у этого сообжения который \n",
      "если вы вимите норкальный или почти норкальный тедст у этого соожбения доторый \n",
      "если вы вимите норкальный или почти норкальный тедст у этого сообшения доторый \n",
      "если вы вимите нордальный или почти нордальный текст у этого сообщения который \n",
      "если вы вимите норкальный или почти норкальный тедст у этого сообжения доторый \n",
      "если вы вимите норжальный или подти норжальный текст у этого сообчения который \n",
      "если вы вимите норжальный или подти норжальный текст у этого сообцения который \n",
      "если вы вимите норшальный или почти норшальный текст у этого соождения который \n",
      "если вы вимите норшальный или подти норшальный текст у этого соожчения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого соожчения который \n",
      "если вы вимите норхальный или подти норхальный текст у этого соожчения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого соожбения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого соожбения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого сообщения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого сообщения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого соошжения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого соожбения который \n",
      "если вы вимите норзальный или подти норзальный текст у чтого сообщения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого соожчения который \n",
      "если вы вимите нордальный или почти нордальный текст у этого сообжения который \n",
      "если вы вимите норжальный или подти норжальный текст у этого сообчения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого соожбения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого сообщения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого сообжения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого соожчения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого соожчения который \n",
      "если вы вимите норкальный или почти норкальный тедст у этого соожбения доторый \n",
      "если вы вимите норзальный или подти норзальный текст у этого сообчения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого сообжения который \n",
      "если вы вимите нордальный или почти нордальный текст у этого сообщения который \n",
      "если вы вимите норкальный или почти норкальный тедст у этого сообшения доторый \n",
      "если вы вимите норшальный или подти норшальный текст у этого сообчения который \n",
      "если вы вимите норбальный или подти норбальный текст у этого соочшения который \n",
      "если вы вимите норжальный или подти норжальный текст у этого соочшения который \n",
      "если вы вимите норжальный или подти норжальный текст у этого соочшения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого соочшения который \n",
      "если вы вимите норчальный или подти норчальный текст у этого сообжения который \n",
      "если вы вимите норчальный или подти норчальный текст у этого сообжения который \n",
      "если вы вимите норжальный или подти норжальный текст у этого сообщения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого сообжения который \n",
      "если вы вимите норзальный или подти норзальный текст у штого сообщения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого сообжения который \n",
      "если вы вимите нордальный или почти нордальный текст у этого соожбения который \n",
      "если вы вимите норшальный или подти норшальный текст у этого соожчения который \n",
      "если вы вимите норшальный или подти норшальный текст у этого соожчения который \n",
      "если вы вимите норбальный или подти норбальный текст у этого соожчения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого сообщения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого сообщения который \n",
      "если вы вимите норжальный или подти норжальный текст у чтого сообщения который \n",
      "если вы вимите норжальный или подти норжальный текст у чтого сообщения который \n",
      "если вы вимите норшальный или подти норшальный текст у этого сообщения который \n",
      "если вы вимите норчальный или подти норчальный текст у этого сообщения который \n",
      "если вы вимите норчальный или подти норчальный текст у этого соожбения который \n",
      "если вы вимите норжальный или подти норжальный текст у этого сообчения который \n",
      "если вы вимите норжальный или подти норжальный текст у этого сообчения который \n",
      "если вы вимите норжальный или подти норжальный текст у этого сообшения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого соочшения который \n",
      "если вы вимите норбальный или подти норбальный текст у этого соочшения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого соочшения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого соочшения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого соочшения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого сообщения который \n",
      "если вы видите норчальный или помти норчальный текст у этого сообщения который \n",
      "если вы видите норзальный или помти норзальный текст у этого сообщения который \n",
      "если вы вимите норжальный или подти норжальный текст у этого сообцения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого сообщения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого сообжения который \n",
      "если вы вимите нордальный или почти нордальный текст у этого сообщения который \n",
      "если вы вимите норбальный или подти норбальный текст у этого соочшения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого соочщения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого сообжения который \n",
      "если вы вимите норчальный или подти норчальный текст у этого сообжения который \n",
      "если вы вимите норчальный или подти норчальный текст у этого сообщения который \n",
      "если вы вимите норчальный или подти норчальный текст у этого сообщения который \n",
      "если вы вимите нордальный или почти нордальный текст у этого сообжения который \n",
      "если вы вимите норчальный или подти норчальный текст у этого соожбения который \n",
      "если вы вимите норшальный или подти норшальный текст у этого сообщения который \n",
      "если вы вимите норзальный или подти норзальный текст у чтого сообщения который \n",
      "если вы вимите норжальный или подти норжальный текст у этого соочшения который \n",
      "если вы вимите норжальный или подти норжальный текст у этого соочшения который \n",
      "если вы вимите норжальный или подти норжальный текст у этого сообшения который \n",
      "если вы вимите норзальный или подти норзальный текст у чтого сообщения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого сообшения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого соочшения который \n",
      "если вы видите норжальный или помти норжальный текст у этого соочшения который \n",
      "если вы вимите норчальный или подти норчальный текст у этого соожцения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого соошчения который \n",
      "если вы вимите норжальный или подти норжальный текст у этого сообщения который \n",
      "если вы вимите норжальный или подти норжальный текст у этого сообщения который \n",
      "если вы вимите норжальный или подти норжальный текст у этого сообщения который \n",
      "если вы вимите норжальный или подти норжальный текст у этого сообчения который \n",
      "если вы вимите норжальный или подти норжальный текст у этого сообчения который \n",
      "если вы вимите норчальный или подти норчальный текст у этого сообщения который \n",
      "если вы вимите норжальный или подти норжальный текст у этого соочшения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого соочшения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого соочшения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого соочшения который \n",
      "если вы вимите норзальный или подти норзальный текст у этого соожчения который \n",
      "если вы вимите норчальный или подти норчальный текст у этого соожбения который \n",
      "если вы вимите норкальный или почти норкальный тедст у этого сообщения доторый \n"
     ]
    }
   ],
   "source": [
    "num_samples = 100000\n",
    "result_decrypt_dict = metropolis_hastings(\n",
    "    lambda x : multinomial_likelihood_logpdf(\n",
    "        x,\n",
    "        text=task_text,\n",
    "        ngramm_database=war_and_peace_count_2gramm,\n",
    "        count_char_in_ngramm=2,\n",
    "    ), \n",
    "    iterations=num_samples, \n",
    "    init_dict_key=result_decrypt_dict,\n",
    "    problem_text=task_text,\n",
    "    print_text=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "если вы вимите нордальный или почти нордальный текст у этого сообщения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный балл за послемнее четвертое замание курса хотя конечно я ничего не обещаш\n"
     ]
    }
   ],
   "source": [
    "decrypt_any_text = encrypt_text(task_text, key_dict=result_decrypt_dict)\n",
    "print(decrypt_any_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вывод\n",
    "\n",
    "Вот прям совсем не сразу, попытки с 15, но текст читается"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Залание 5 (бонус): \n",
    "\n",
    "А что если от биграмм перейти к триграммам (тройкам букв) или даже больше? Улучшатся ли результаты? Когда улучшатся, а когда нет? Чтобы ответить на этот вопрос эмпирически, уже может понадобиться погенерировать много тестовых перестановок и последить за метриками, глазами может быть и не видно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Решение\n",
    "\n",
    "Рассмотрим тексты различной длины из романа Анна Каренина и оценим точность расшифровки на биграммах и триграммах. Для набора статистики повторим данный процес для каждого теста 100 раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_and_peace_count_3gramm = calculate_ngramm(war_and_peace, count_char_in_ngramm=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ожриеыкеыизисоеяаню рчяклеириеьавсиеяаню рчяклесопжседеусайаежаагбояихепасанкле\n",
      "икра сы сазали новтержным ара дошла новтержным липкл у глохо коофциная половым \n",
      "икла сы сазари новшельных ала домра новшельных риткр у прого коожчиная торовых \n",
      "есла вы вазате норжильный ала дошта норжильный текст у хтого соочбеная который \n",
      "если вы видите норжальный или почти норжальный текст у этого сообшения который \n",
      "если вы видите норжальный или почти норжальный текст у этого сообщения который \n",
      "если вы видите нормальный или почти нормальный текст у этого сообщения который \n",
      "если вы видите нормальный или почти нормальный текст у этого сообщения который \n",
      "если вы видите нормальный или почти нормальный текст у этого сообщения который \n",
      "если вы видите нормальный или почти нормальный текст у этого сообщения который \n"
     ]
    }
   ],
   "source": [
    "num_samples = 10000\n",
    "result_decrypt_dict = metropolis_hastings(\n",
    "    lambda x : multinomial_likelihood_logpdf(\n",
    "        x,\n",
    "        text=task_text,\n",
    "        ngramm_database=war_and_peace_count_3gramm,\n",
    "        count_char_in_ngramm=3,\n",
    "    ), \n",
    "    iterations=num_samples, \n",
    "    init_dict_key=decrypt_dict_for_task,\n",
    "    problem_text=task_text,\n",
    "    print_text=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0b0b56dc5946d4b2bc86581687f3ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "array_length_text = [20, 50, 100, 200, 500, 1000]\n",
    "num_samples = 10000\n",
    "\n",
    "accuracy_2_gram = []\n",
    "accuracy_3_gram = []\n",
    "\n",
    "COUNT_SAMPLE = 100\n",
    "for _ in tqdm(range(COUNT_SAMPLE)):\n",
    "    for _length in array_length_text:\n",
    "\n",
    "        input_text = anna_karenina[4:_length]\n",
    "        encrypt_input_text = encrypt_text(input_text, key_dict=encrypt_dict)\n",
    "\n",
    "        decrypt_dict = dict(zip(ABC, ABC))\n",
    "        result_decrypt_dict = metropolis_hastings(\n",
    "            lambda x : multinomial_likelihood_logpdf(\n",
    "                x,\n",
    "                text=encrypt_input_text,\n",
    "                ngramm_database=war_and_peace_count_2gramm,\n",
    "                count_char_in_ngramm=2,\n",
    "            ), \n",
    "            iterations=num_samples, \n",
    "            init_dict_key=decrypt_dict,\n",
    "            problem_text=encrypt_input_text,\n",
    "        )\n",
    "        decrypt_input_text = encrypt_text(encrypt_input_text, key_dict=result_decrypt_dict)\n",
    "        accuracy_2_gram.append(accuracy_decrypt(input_text, decrypt_input_text))\n",
    "\n",
    "        # 3-gram\n",
    "        decrypt_dict = dict(zip(ABC, ABC))\n",
    "        result_decrypt_dict = metropolis_hastings(\n",
    "            lambda x : multinomial_likelihood_logpdf(\n",
    "                x,\n",
    "                text=encrypt_input_text,\n",
    "                ngramm_database=war_and_peace_count_3gramm,\n",
    "                count_char_in_ngramm=3\n",
    "            ), \n",
    "            iterations=num_samples, \n",
    "            init_dict_key=decrypt_dict,\n",
    "            problem_text=encrypt_input_text,\n",
    "#             print_text=True\n",
    "        )\n",
    "        decrypt_input_text = encrypt_text(encrypt_input_text, key_dict=result_decrypt_dict)\n",
    "        accuracy_3_gram.append(accuracy_decrypt(input_text, decrypt_input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_dict = {\n",
    "    'count_char': array_length_text * COUNT_SAMPLE * 2,\n",
    "    'accuracy': accuracy_2_gram + accuracy_3_gram,\n",
    "    'count_gram': ['2_gram'] * len(accuracy_2_gram) + ['3_gram'] * len(accuracy_3_gram)\n",
    "}\n",
    "\n",
    "analyze_df = pd.DataFrame(analyze_dict)\n",
    "analyze_df.to_csv('analyze_metropolis_hastings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyze_df = pd.read_csv('analyze_metropolis_hastings.csv')\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "ax = sns.boxplot(x=\"count_char\", y=\"accuracy\", hue=\"count_gram\",\n",
    "                 data=analyze_df)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вывод\n",
    "\n",
    "- триграммы делают точность более стабильной, которая растет с увеличением количесвтва символов в тесте. \n",
    "- точность по триграммам стабильно выше, чем по биграмма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6 (бонус) \n",
    "\n",
    "Какие вы можете придумать применения для этой модели? Пляшущие человечки ведь не так часто встречаются в жизни (хотя встречаются! и это самое потрясающее во всей этой истории, но об этом я расскажу потом)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ответ\n",
    "\n",
    "Распределение букв в больших текстах подчиняется степенному закону. Можно распространить идею МСМС-семлирования на распределения, которые подчиняются степенному закону, т.е. те распределения, для которых уже наблюдается некая упрощенная зависимость и можно сделать эту зависимость более \"глубокой\".\n",
    "\n",
    "Например:\n",
    "\n",
    "Взято из Википедии: \"Аллометрические закономерности для отношений между биологическими переменными являются одними из самых известных примеров степенных законов в природе.\" (Аллометрия - неравномерный рост частей тела)\n",
    "\n",
    "Т.е. зная изменение размеров частей тела у животного можно корректно описать этапы эволюции этого животного"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
